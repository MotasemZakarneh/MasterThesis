{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as plotlib\n",
    "import JG_Helpers as jg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# Excercise 1: Draw a Square using neural networks\n",
    "\n",
    "# let there be two input neurons [5,15]\n",
    "# recall:\n",
    "#z = dot(wjk,yk1) + bj\n",
    "#j = output\n",
    "#k = input\n",
    "\n",
    "# solution\n",
    "# let there be 4 intermediate neurons such that\n",
    "\n",
    "#       *               #output (fz) jump\n",
    "# *   *   *   *         #hidden layer of neurons\n",
    "#     *   *             #input neurons\n",
    "\n",
    "# each neuron will have weigths (arrows) connected to each neuron in the next layer\n",
    "y_in = [5, 15]  # the point that we want to test\n",
    "\n",
    "# logically this is correct, code wise, its against how we build things\n",
    "# weigths = [\n",
    "#     [1.0,1.0,1.0,1.0], #first neuron weigths to the hidden layer\n",
    "#     [1.0,1.0,1.0,1.0]  #second neuron weigths to the hidden layer\n",
    "# ]\n",
    "\n",
    "# Data Values:\n",
    "weigths_hidden = [\n",
    "    # n1_weigth,n2_weigth\n",
    "    [0.5, 0.5],  # weigths to first neuron in hidden layer\n",
    "    [0.5, 0.5],  # weigths to second neuron in hidden layer\n",
    "    [0.5, 0.5],  # weigths to third neuron in hidden layer\n",
    "    [0.5, 0.5]  # weigths to fourth neuron in hidden layer\n",
    "]\n",
    "\n",
    "# biases for hidden layer #jump is around 0, so offset by size of square\n",
    "biases_hidden = [-10.0, -10, -10, -10]  \n",
    "\n",
    "res = jg.apply_layer(y_in, weigths_hidden, biases_hidden, jg.activation_jump)\n",
    "print(res)\n",
    "\n",
    "# these values should be mapping directly from hidden layer to final layer\n",
    "\n",
    "# weigths from the hidden layter to the output layer,\n",
    "# i suggest that in this case, they are assigned\n",
    "weigths_to_out = [\n",
    "    1.0,  # first neuron in hidden weigth to out\n",
    "    1,  # second neuron in hidden weigth to out\n",
    "    1,  # third neuron in hidden weigth to out\n",
    "    1  # fourth neuron in hidden weigth to out\n",
    "]\n",
    "\n",
    "# only a single output neuron, no need to offset it\n",
    "# offsetting was made to the output\n",
    "biases_to_out = [0.0]\n",
    "res = jg.apply_layer(res, weigths_to_out, biases_to_out, jg.activation_jump)\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a46a4a04ddb101ba9c63fe9824c5a1b5241bba42b520c4e7666929978509d7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
